# RunPod Serverless Dockerfile for Chandra OCR (Lazy Loading Version)
# 修復重點:
# 1. 移除 flash-attention (Optional,會導致 Build 超時)
# 2. 移除 Model 預下載 (改用 RunPod Runtime 下載,利用優化網路 60MB/s)
# 3. 正確的環境變數配置

FROM nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV TORCH_HOME=/app/.cache/torch
ENV HF_HOME=/app/.cache/huggingface
ENV MODEL_CHECKPOINT=datalab-to/chandra
ENV TORCH_DEVICE=cuda
ENV MAX_OUTPUT_TOKENS=12384

# Install system dependencies
RUN apt-get update && apt-get install -y \
    python3.10 \
    python3-pip \
    git \
    wget \
    curl \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    && rm -rf /var/lib/apt/lists/*

# Upgrade pip
RUN pip3 install --no-cache-dir --upgrade pip

# Set working directory
WORKDIR /app

# Copy project files
COPY . /app/

# Install Python dependencies
# ✅ 移除 flash-attn (Optional,會導致 Build 超時)
RUN pip3 install --no-cache-dir -e . && \
    pip3 install --no-cache-dir runpod requests

# Create cache directories
RUN mkdir -p /app/.cache/torch /app/.cache/huggingface

# ✅ 移除 Model 預下載 (改用 Lazy Loading)
# 理由:
# 1. GitHub Actions 磁碟空間不足 (14GB vs 22GB 需求)
# 2. RunPod Runtime 下載更快 (60 MB/s 優化網路 vs 5-10 MB/s GitHub)
# 3. 首次冷啟動 2 分鐘可接受,後續啟動 15-20 秒
# Model 會在 runpod_handler.py 首次請求時自動下載

# Set the entrypoint
CMD ["python3", "-u", "runpod_handler.py"]
